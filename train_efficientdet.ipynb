{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# setup dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import stuff\n",
    "import os\n",
    "import numpy as np\n",
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.utils.data as data\n",
    "from itertools import product as product\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.init as init\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import dataset\n",
    "from utils.dataset import VOCDataset, DatasetTransform, make_datapath_list, Anno_xml2list, od_collate_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select from efficientnet backbone or resnet backbone\n",
    "backbone = \"efficientnetb0\"\n",
    "scale = 1\n",
    "# scale==1: resolution 300\n",
    "# scale==2: resolution 600"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## make data.Dataset for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainlist:  16551\n",
      "vallist:  4952\n"
     ]
    }
   ],
   "source": [
    "# load files\n",
    "# set your VOCdevkit path here.\n",
    "vocpath = \"../VOCdevkit/VOC2007\"\n",
    "train_img_list, train_anno_list, val_img_list, val_anno_list = make_datapath_list(vocpath)\n",
    "\n",
    "vocpath = \"../VOCdevkit/VOC2012\"\n",
    "train_img_list2, train_anno_list2, _, _ = make_datapath_list(vocpath)\n",
    "\n",
    "train_img_list.extend(train_img_list2)\n",
    "train_anno_list.extend(train_anno_list2)\n",
    "\n",
    "print(\"trainlist: \", len(train_img_list))\n",
    "print(\"vallist: \", len(val_img_list))\n",
    "\n",
    "# make Dataset\n",
    "voc_classes = ['aeroplane', 'bicycle', 'bird', 'boat',\n",
    "               'bottle', 'bus', 'car', 'cat', 'chair',\n",
    "               'cow', 'diningtable', 'dog', 'horse',\n",
    "               'motorbike', 'person', 'pottedplant',\n",
    "               'sheep', 'sofa', 'train', 'tvmonitor']\n",
    "\n",
    "color_mean = (104, 117, 123)  # (BGR)の色の平均値\n",
    "input_size = 300*scale  # 画像のinputサイズを300×300にする\n",
    "\n",
    "## DatasetTransformを適応\n",
    "transform = DatasetTransform(input_size, color_mean)\n",
    "transform_anno = Anno_xml2list(voc_classes)\n",
    "\n",
    "# Dataloaderに入れるデータセットファイル。\n",
    "# ゲットで叩くと画像とGTを前処理して出力してくれる。\n",
    "train_dataset = VOCDataset(train_img_list, train_anno_list, phase = \"train\", transform=transform, transform_anno = transform_anno)\n",
    "val_dataset = VOCDataset(val_img_list, val_anno_list, phase=\"val\", transform=DatasetTransform(\n",
    "    input_size, color_mean), transform_anno=Anno_xml2list(voc_classes))\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "train_dataloader = data.DataLoader(\n",
    "    train_dataset, batch_size=batch_size, shuffle=True, collate_fn=od_collate_fn, num_workers=8)\n",
    "\n",
    "val_dataloader = data.DataLoader(\n",
    "    val_dataset, batch_size=batch_size, shuffle=False, collate_fn=od_collate_fn, num_workers=8)\n",
    "\n",
    "# 辞書型変数にまとめる\n",
    "dataloaders_dict = {\"train\": train_dataloader, \"val\": val_dataloader}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 3, 300, 300])\n",
      "32\n",
      "torch.Size([1, 5])\n"
     ]
    }
   ],
   "source": [
    "# 動作の確認\n",
    "batch_iterator = iter(dataloaders_dict[\"val\"])  # イタレータに変換\n",
    "images, targets = next(batch_iterator)  # 1番目の要素を取り出す\n",
    "print(images.size())  # torch.Size([4, 3, 300, 300])\n",
    "print(len(targets))\n",
    "print(targets[1].shape)  # ミニバッチのサイズのリスト、各要素は[n, 5]、nは物体数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# define EfficientDet model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.efficientdet import EfficientDet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained weights for efficientnet-b0\n",
      "layerc3: torch.Size([1, 40, 37, 37])\n",
      "layerc4: torch.Size([1, 80, 18, 18])\n",
      "layerc5: torch.Size([1, 320, 9, 9])\n",
      "layer size: torch.Size([1, 256, 37, 37])\n",
      "layer size: torch.Size([1, 256, 18, 18])\n",
      "layer size: torch.Size([1, 256, 9, 9])\n",
      "layer size: torch.Size([1, 256, 5, 5])\n",
      "layer size: torch.Size([1, 256, 3, 3])\n",
      "layer size: torch.Size([1, 256, 1, 1])\n",
      "torch.Size([1, 8096, 4])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/torch/nn/functional.py:2457: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\n",
      "  warnings.warn(\"nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\")\n",
      "/home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/torch/nn/functional.py:2539: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
      "  \"See the documentation of nn.Upsample for details.\".format(mode))\n"
     ]
    }
   ],
   "source": [
    "if scale==1:\n",
    "    ssd_cfg = {\n",
    "        'num_classes': 21,  # 背景クラスを含めた合計クラス数\n",
    "        'input_size': 300*scale,  # 画像の入力サイズ\n",
    "        'bbox_aspect_num': [4, 6, 6, 6, 4, 4],  # 出力するDBoxのアスペクト比の種類\n",
    "        'feature_maps': [37, 18, 9, 5, 3, 1],  # 各sourceの画像サイズ\n",
    "        'steps': [8, 16, 32, 64, 100, 300],  # DBOXの大きさを決める\n",
    "        'min_sizes': [30, 60, 111, 162, 213, 264],  # DBOXの大きさを決める\n",
    "        'max_sizes': [60, 111, 162, 213, 264, 315],  # DBOXの大きさを決める\n",
    "        'aspect_ratios': [[2], [2, 3], [2, 3], [2, 3], [2], [2]],\n",
    "    }\n",
    "elif scale==2:\n",
    "    ssd_cfg = {\n",
    "        'num_classes': 21,  # 背景クラスを含めた合計クラス数\n",
    "        'input_size': 300*scale,  # 画像の入力サイズ\n",
    "        'bbox_aspect_num': [4, 6, 6, 6, 4, 4],  # 出力するDBoxのアスペクト比の種類\n",
    "        'feature_maps': [75, 38, 19, 10, 5, 3],  # 各sourceの画像サイズ\n",
    "        'steps': [8, 16, 32, 64, 100, 300],  # DBOXの大きさを決める\n",
    "        'min_sizes': [30, 60, 111, 162, 213, 264]*scale,  # DBOXの大きさを決める\n",
    "        'max_sizes': [60, 111, 162, 213, 264, 315]*scale,  # DBOXの大きさを決める\n",
    "        'aspect_ratios': [[2], [2, 3], [2, 3], [2, 3], [2], [2]],\n",
    "    }\n",
    "\n",
    "# test if net works\n",
    "net = EfficientDet(phase=\"train\", cfg=ssd_cfg, verbose=True)\n",
    "out = net(torch.rand([1,3,300,300]))\n",
    "print(out[0].size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained weights for efficientnet-b0\n",
      "using: cuda:0\n",
      "set weights!\n"
     ]
    }
   ],
   "source": [
    "net = EfficientDet(phase=\"train\", cfg=ssd_cfg, verbose=False)\n",
    "\n",
    "# GPUが使えるか確認\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"using:\", device)\n",
    "\n",
    "print(\"set weights!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EfficientDet(\n",
      "  (layer0): Sequential(\n",
      "    (0): Conv2dStaticSamePadding(\n",
      "      3, 32, kernel_size=(3, 3), stride=(2, 2), bias=False\n",
      "      (static_padding): ZeroPad2d(padding=(0, 1, 0, 1), value=0.0)\n",
      "    )\n",
      "    (1): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): MBConvBlock(\n",
      "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
      "        32, 32, kernel_size=(3, 3), stride=[1, 1], groups=32, bias=False\n",
      "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
      "      )\n",
      "      (_bn1): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_se_reduce): Conv2dStaticSamePadding(\n",
      "        32, 8, kernel_size=(1, 1), stride=(1, 1)\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_se_expand): Conv2dStaticSamePadding(\n",
      "        8, 32, kernel_size=(1, 1), stride=(1, 1)\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_project_conv): Conv2dStaticSamePadding(\n",
      "        32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_bn2): BatchNorm2d(16, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_swish): MemoryEfficientSwish()\n",
      "    )\n",
      "    (1): MBConvBlock(\n",
      "      (_expand_conv): Conv2dStaticSamePadding(\n",
      "        16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_bn0): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
      "        96, 96, kernel_size=(3, 3), stride=[2, 2], groups=96, bias=False\n",
      "        (static_padding): ZeroPad2d(padding=(0, 1, 0, 1), value=0.0)\n",
      "      )\n",
      "      (_bn1): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_se_reduce): Conv2dStaticSamePadding(\n",
      "        96, 4, kernel_size=(1, 1), stride=(1, 1)\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_se_expand): Conv2dStaticSamePadding(\n",
      "        4, 96, kernel_size=(1, 1), stride=(1, 1)\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_project_conv): Conv2dStaticSamePadding(\n",
      "        96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_bn2): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_swish): MemoryEfficientSwish()\n",
      "    )\n",
      "    (2): MBConvBlock(\n",
      "      (_expand_conv): Conv2dStaticSamePadding(\n",
      "        24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_bn0): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
      "        144, 144, kernel_size=(3, 3), stride=(1, 1), groups=144, bias=False\n",
      "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
      "      )\n",
      "      (_bn1): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_se_reduce): Conv2dStaticSamePadding(\n",
      "        144, 6, kernel_size=(1, 1), stride=(1, 1)\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_se_expand): Conv2dStaticSamePadding(\n",
      "        6, 144, kernel_size=(1, 1), stride=(1, 1)\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_project_conv): Conv2dStaticSamePadding(\n",
      "        144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_bn2): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_swish): MemoryEfficientSwish()\n",
      "    )\n",
      "    (3): MBConvBlock(\n",
      "      (_expand_conv): Conv2dStaticSamePadding(\n",
      "        24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_bn0): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
      "        144, 144, kernel_size=(5, 5), stride=[2, 2], groups=144, bias=False\n",
      "        (static_padding): ZeroPad2d(padding=(1, 2, 1, 2), value=0.0)\n",
      "      )\n",
      "      (_bn1): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_se_reduce): Conv2dStaticSamePadding(\n",
      "        144, 6, kernel_size=(1, 1), stride=(1, 1)\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_se_expand): Conv2dStaticSamePadding(\n",
      "        6, 144, kernel_size=(1, 1), stride=(1, 1)\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_project_conv): Conv2dStaticSamePadding(\n",
      "        144, 40, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_bn2): BatchNorm2d(40, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_swish): MemoryEfficientSwish()\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): MBConvBlock(\n",
      "      (_expand_conv): Conv2dStaticSamePadding(\n",
      "        40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_bn0): BatchNorm2d(240, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
      "        240, 240, kernel_size=(5, 5), stride=(1, 1), groups=240, bias=False\n",
      "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
      "      )\n",
      "      (_bn1): BatchNorm2d(240, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_se_reduce): Conv2dStaticSamePadding(\n",
      "        240, 10, kernel_size=(1, 1), stride=(1, 1)\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_se_expand): Conv2dStaticSamePadding(\n",
      "        10, 240, kernel_size=(1, 1), stride=(1, 1)\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_project_conv): Conv2dStaticSamePadding(\n",
      "        240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_bn2): BatchNorm2d(40, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_swish): MemoryEfficientSwish()\n",
      "    )\n",
      "    (1): MBConvBlock(\n",
      "      (_expand_conv): Conv2dStaticSamePadding(\n",
      "        40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_bn0): BatchNorm2d(240, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
      "        240, 240, kernel_size=(3, 3), stride=[2, 2], groups=240, bias=False\n",
      "        (static_padding): ZeroPad2d(padding=(0, 1, 0, 1), value=0.0)\n",
      "      )\n",
      "      (_bn1): BatchNorm2d(240, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_se_reduce): Conv2dStaticSamePadding(\n",
      "        240, 10, kernel_size=(1, 1), stride=(1, 1)\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_se_expand): Conv2dStaticSamePadding(\n",
      "        10, 240, kernel_size=(1, 1), stride=(1, 1)\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_project_conv): Conv2dStaticSamePadding(\n",
      "        240, 80, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_bn2): BatchNorm2d(80, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_swish): MemoryEfficientSwish()\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): MBConvBlock(\n",
      "      (_expand_conv): Conv2dStaticSamePadding(\n",
      "        80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_bn0): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
      "        480, 480, kernel_size=(3, 3), stride=(1, 1), groups=480, bias=False\n",
      "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
      "      )\n",
      "      (_bn1): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_se_reduce): Conv2dStaticSamePadding(\n",
      "        480, 20, kernel_size=(1, 1), stride=(1, 1)\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_se_expand): Conv2dStaticSamePadding(\n",
      "        20, 480, kernel_size=(1, 1), stride=(1, 1)\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_project_conv): Conv2dStaticSamePadding(\n",
      "        480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_bn2): BatchNorm2d(80, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_swish): MemoryEfficientSwish()\n",
      "    )\n",
      "    (1): MBConvBlock(\n",
      "      (_expand_conv): Conv2dStaticSamePadding(\n",
      "        80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_bn0): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
      "        480, 480, kernel_size=(3, 3), stride=(1, 1), groups=480, bias=False\n",
      "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
      "      )\n",
      "      (_bn1): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_se_reduce): Conv2dStaticSamePadding(\n",
      "        480, 20, kernel_size=(1, 1), stride=(1, 1)\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_se_expand): Conv2dStaticSamePadding(\n",
      "        20, 480, kernel_size=(1, 1), stride=(1, 1)\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_project_conv): Conv2dStaticSamePadding(\n",
      "        480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_bn2): BatchNorm2d(80, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_swish): MemoryEfficientSwish()\n",
      "    )\n",
      "    (2): MBConvBlock(\n",
      "      (_expand_conv): Conv2dStaticSamePadding(\n",
      "        80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_bn0): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
      "        480, 480, kernel_size=(5, 5), stride=[1, 1], groups=480, bias=False\n",
      "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
      "      )\n",
      "      (_bn1): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_se_reduce): Conv2dStaticSamePadding(\n",
      "        480, 20, kernel_size=(1, 1), stride=(1, 1)\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_se_expand): Conv2dStaticSamePadding(\n",
      "        20, 480, kernel_size=(1, 1), stride=(1, 1)\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_project_conv): Conv2dStaticSamePadding(\n",
      "        480, 112, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_bn2): BatchNorm2d(112, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_swish): MemoryEfficientSwish()\n",
      "    )\n",
      "    (3): MBConvBlock(\n",
      "      (_expand_conv): Conv2dStaticSamePadding(\n",
      "        112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_bn0): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
      "        672, 672, kernel_size=(5, 5), stride=(1, 1), groups=672, bias=False\n",
      "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
      "      )\n",
      "      (_bn1): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_se_reduce): Conv2dStaticSamePadding(\n",
      "        672, 28, kernel_size=(1, 1), stride=(1, 1)\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_se_expand): Conv2dStaticSamePadding(\n",
      "        28, 672, kernel_size=(1, 1), stride=(1, 1)\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_project_conv): Conv2dStaticSamePadding(\n",
      "        672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_bn2): BatchNorm2d(112, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_swish): MemoryEfficientSwish()\n",
      "    )\n",
      "    (4): MBConvBlock(\n",
      "      (_expand_conv): Conv2dStaticSamePadding(\n",
      "        112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_bn0): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
      "        672, 672, kernel_size=(5, 5), stride=(1, 1), groups=672, bias=False\n",
      "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
      "      )\n",
      "      (_bn1): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_se_reduce): Conv2dStaticSamePadding(\n",
      "        672, 28, kernel_size=(1, 1), stride=(1, 1)\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_se_expand): Conv2dStaticSamePadding(\n",
      "        28, 672, kernel_size=(1, 1), stride=(1, 1)\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_project_conv): Conv2dStaticSamePadding(\n",
      "        672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_bn2): BatchNorm2d(112, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_swish): MemoryEfficientSwish()\n",
      "    )\n",
      "    (5): MBConvBlock(\n",
      "      (_expand_conv): Conv2dStaticSamePadding(\n",
      "        112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_bn0): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
      "        672, 672, kernel_size=(5, 5), stride=[2, 2], groups=672, bias=False\n",
      "        (static_padding): ZeroPad2d(padding=(1, 2, 1, 2), value=0.0)\n",
      "      )\n",
      "      (_bn1): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_se_reduce): Conv2dStaticSamePadding(\n",
      "        672, 28, kernel_size=(1, 1), stride=(1, 1)\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_se_expand): Conv2dStaticSamePadding(\n",
      "        28, 672, kernel_size=(1, 1), stride=(1, 1)\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_project_conv): Conv2dStaticSamePadding(\n",
      "        672, 192, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_bn2): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_swish): MemoryEfficientSwish()\n",
      "    )\n",
      "  )\n",
      "  (layer5): Sequential(\n",
      "    (0): MBConvBlock(\n",
      "      (_expand_conv): Conv2dStaticSamePadding(\n",
      "        192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_bn0): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
      "        1152, 1152, kernel_size=(5, 5), stride=(1, 1), groups=1152, bias=False\n",
      "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
      "      )\n",
      "      (_bn1): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_se_reduce): Conv2dStaticSamePadding(\n",
      "        1152, 48, kernel_size=(1, 1), stride=(1, 1)\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_se_expand): Conv2dStaticSamePadding(\n",
      "        48, 1152, kernel_size=(1, 1), stride=(1, 1)\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_project_conv): Conv2dStaticSamePadding(\n",
      "        1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_bn2): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_swish): MemoryEfficientSwish()\n",
      "    )\n",
      "    (1): MBConvBlock(\n",
      "      (_expand_conv): Conv2dStaticSamePadding(\n",
      "        192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_bn0): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
      "        1152, 1152, kernel_size=(5, 5), stride=(1, 1), groups=1152, bias=False\n",
      "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
      "      )\n",
      "      (_bn1): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_se_reduce): Conv2dStaticSamePadding(\n",
      "        1152, 48, kernel_size=(1, 1), stride=(1, 1)\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_se_expand): Conv2dStaticSamePadding(\n",
      "        48, 1152, kernel_size=(1, 1), stride=(1, 1)\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_project_conv): Conv2dStaticSamePadding(\n",
      "        1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_bn2): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_swish): MemoryEfficientSwish()\n",
      "    )\n",
      "    (2): MBConvBlock(\n",
      "      (_expand_conv): Conv2dStaticSamePadding(\n",
      "        192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_bn0): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
      "        1152, 1152, kernel_size=(5, 5), stride=(1, 1), groups=1152, bias=False\n",
      "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
      "      )\n",
      "      (_bn1): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_se_reduce): Conv2dStaticSamePadding(\n",
      "        1152, 48, kernel_size=(1, 1), stride=(1, 1)\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_se_expand): Conv2dStaticSamePadding(\n",
      "        48, 1152, kernel_size=(1, 1), stride=(1, 1)\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_project_conv): Conv2dStaticSamePadding(\n",
      "        1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_bn2): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_swish): MemoryEfficientSwish()\n",
      "    )\n",
      "    (3): MBConvBlock(\n",
      "      (_expand_conv): Conv2dStaticSamePadding(\n",
      "        192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_bn0): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
      "        1152, 1152, kernel_size=(3, 3), stride=[1, 1], groups=1152, bias=False\n",
      "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
      "      )\n",
      "      (_bn1): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_se_reduce): Conv2dStaticSamePadding(\n",
      "        1152, 48, kernel_size=(1, 1), stride=(1, 1)\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_se_expand): Conv2dStaticSamePadding(\n",
      "        48, 1152, kernel_size=(1, 1), stride=(1, 1)\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_project_conv): Conv2dStaticSamePadding(\n",
      "        1152, 320, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_bn2): BatchNorm2d(320, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_swish): MemoryEfficientSwish()\n",
      "    )\n",
      "  )\n",
      "  (conv6): Conv2d(320, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "  (conv7): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "  (conv8): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (toplayer): Conv2d(320, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "  (smooth1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (smooth2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (latlayer1): Conv2d(80, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "  (latlayer2): Conv2d(40, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "  (loc): ModuleList(\n",
      "    (0): Conv2d(256, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): Conv2d(256, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (2): Conv2d(256, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): Conv2d(256, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (4): Conv2d(256, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (5): Conv2d(256, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  )\n",
      "  (conf): ModuleList(\n",
      "    (0): Conv2d(256, 84, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): Conv2d(256, 126, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (2): Conv2d(256, 126, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): Conv2d(256, 126, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (4): Conv2d(256, 84, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (5): Conv2d(256, 84, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.ssd_model import MultiBoxLoss\n",
    "\n",
    "# define loss\n",
    "criterion = MultiBoxLoss(jaccard_thresh=0.5,neg_pos=3, device=device)\n",
    "\n",
    "# optim\n",
    "import torch.optim as optim\n",
    "optimizer = optim.SGD(net.parameters(), lr=1e-3, momentum=0.9, weight_decay=5e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_current_lr(epoch):\n",
    "    lr = 1e-3\n",
    "    for i,lr_decay_epoch in enumerate([120,180]):\n",
    "        if epoch >= lr_decay_epoch:\n",
    "            lr *= 0.1\n",
    "    return lr\n",
    "\n",
    "def adjust_learning_rate(optimizer, epoch):\n",
    "    lr = get_current_lr(epoch)\n",
    "    print(\"lr is:\", lr)\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# モデルを学習させる関数を作成\n",
    "\n",
    "\n",
    "def train_model(net, dataloaders_dict, criterion, optimizer, num_epochs):\n",
    "\n",
    "    # GPUが使えるかを確認\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(\"used device:\", device)\n",
    "\n",
    "    # ネットワークをGPUへ\n",
    "    net.to(device)\n",
    "\n",
    "    # ネットワークがある程度固定であれば、高速化させる\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "\n",
    "    # イテレーションカウンタをセット\n",
    "    iteration = 1\n",
    "    epoch_train_loss = 0.0  # epochの損失和\n",
    "    epoch_val_loss = 0.0  # epochの損失和\n",
    "    logs = []\n",
    "\n",
    "    # epochのループ\n",
    "    for epoch in range(num_epochs+1):\n",
    "        \n",
    "        adjust_learning_rate(optimizer, epoch)\n",
    "        \n",
    "        # 開始時刻を保存\n",
    "        t_epoch_start = time.time()\n",
    "        t_iter_start = time.time()\n",
    "\n",
    "        print('-------------')\n",
    "        print('Epoch {}/{}'.format(epoch+1, num_epochs))\n",
    "        print('-------------')\n",
    "\n",
    "        # epochごとの訓練と検証のループ\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                net.train()  # モデルを訓練モードに\n",
    "                print('(train)')\n",
    "            else:\n",
    "                if((epoch+1) % 10 == 0):\n",
    "                    net.eval()   # モデルを検証モードに\n",
    "                    print('-------------')\n",
    "                    print('(val)')\n",
    "                else:\n",
    "                    # 検証は10回に1回だけ行う\n",
    "                    continue\n",
    "\n",
    "            # データローダーからminibatchずつ取り出すループ\n",
    "            for images, targets in dataloaders_dict[phase]:\n",
    "\n",
    "                # GPUが使えるならGPUにデータを送る\n",
    "                images = images.to(device)\n",
    "                targets = [ann.to(device)\n",
    "                           for ann in targets]  # リストの各要素のテンソルをGPUへ\n",
    "\n",
    "                # optimizerを初期化\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # 順伝搬（forward）計算\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    # 順伝搬（forward）計算\n",
    "                    outputs = net(images)\n",
    "\n",
    "                    # 損失の計算\n",
    "                    loss_l, loss_c = criterion(outputs, targets)\n",
    "                    loss = loss_l + loss_c\n",
    "\n",
    "                    # 訓練時はバックプロパゲーション\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()  # 勾配の計算\n",
    "\n",
    "                        # 勾配が大きくなりすぎると計算が不安定になるので、clipで最大でも勾配2.0に留める\n",
    "                        nn.utils.clip_grad_value_(\n",
    "                            net.parameters(), clip_value=2.0)\n",
    "\n",
    "                        optimizer.step()  # パラメータ更新\n",
    "\n",
    "                        if (iteration % 10 == 0):  # 10iterに1度、lossを表示\n",
    "                            t_iter_finish = time.time()\n",
    "                            duration = t_iter_finish - t_iter_start\n",
    "                            print('Iter {} || Loss: {:.4f} || 10iter: {:.4f} sec.'.format(\n",
    "                                iteration, loss.item(), duration))\n",
    "                            t_iter_start = time.time()\n",
    "\n",
    "                        epoch_train_loss += loss.item()\n",
    "                        iteration += 1\n",
    "\n",
    "                    # 検証時\n",
    "                    else:\n",
    "                        epoch_val_loss += loss.item()\n",
    "\n",
    "        # epochのphaseごとのlossと正解率\n",
    "        t_epoch_finish = time.time()\n",
    "        print('-------------')\n",
    "        print('epoch {} || Epoch_TRAIN_Loss:{:.4f} ||Epoch_VAL_Loss:{:.4f}'.format(\n",
    "            epoch+1, epoch_train_loss, epoch_val_loss))\n",
    "        print('timer:  {:.4f} sec.'.format(t_epoch_finish - t_epoch_start))\n",
    "        t_epoch_start = time.time()\n",
    "\n",
    "        # ログを保存\n",
    "        log_epoch = {'epoch': epoch+1,\n",
    "                     'train_loss': epoch_train_loss, 'val_loss': epoch_val_loss}\n",
    "        logs.append(log_epoch)\n",
    "        df = pd.DataFrame(logs)\n",
    "        df.to_csv(\"log_output.csv\")\n",
    "\n",
    "        epoch_train_loss = 0.0  # epochの損失和\n",
    "        epoch_val_loss = 0.0  # epochの損失和\n",
    "\n",
    "        # ネットワークを保存する\n",
    "        if ((epoch+1) % 10 == 0):\n",
    "            torch.save(net.state_dict(), 'weights/efficientdetd0' + str(300*scale) + \"_\" + \n",
    "                       str(epoch+1) + '.pth')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "used device: cuda:0\n",
      "lr is: 0.001\n",
      "-------------\n",
      "Epoch 1/200\n",
      "-------------\n",
      "(train)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/torch/nn/functional.py:2457: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\n",
      "  warnings.warn(\"nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\")\n",
      "/home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/torch/nn/functional.py:2539: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
      "  \"See the documentation of nn.Upsample for details.\".format(mode))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 10 || Loss: 29.6469 || 10iter: 5.7856 sec.\n",
      "Iter 20 || Loss: 27.7266 || 10iter: 2.5724 sec.\n",
      "Iter 30 || Loss: 22.7666 || 10iter: 2.3900 sec.\n",
      "Iter 40 || Loss: 20.2654 || 10iter: 2.4015 sec.\n",
      "Iter 50 || Loss: 19.1678 || 10iter: 2.5208 sec.\n",
      "Iter 60 || Loss: 17.8210 || 10iter: 2.4121 sec.\n",
      "Iter 70 || Loss: 16.9245 || 10iter: 2.4418 sec.\n",
      "Iter 80 || Loss: 16.1897 || 10iter: 2.4140 sec.\n",
      "Iter 90 || Loss: 15.3084 || 10iter: 2.4101 sec.\n",
      "Iter 100 || Loss: 15.1703 || 10iter: 2.4014 sec.\n",
      "Iter 110 || Loss: 13.9548 || 10iter: 2.3977 sec.\n",
      "Iter 120 || Loss: 13.1043 || 10iter: 2.4734 sec.\n",
      "Iter 130 || Loss: 12.4970 || 10iter: 2.4313 sec.\n",
      "Iter 140 || Loss: 11.9180 || 10iter: 2.4973 sec.\n",
      "Iter 150 || Loss: 10.7936 || 10iter: 2.4723 sec.\n",
      "Iter 160 || Loss: 10.2956 || 10iter: 2.4339 sec.\n",
      "Iter 170 || Loss: 11.9987 || 10iter: 2.4240 sec.\n",
      "Iter 180 || Loss: 10.1595 || 10iter: 2.4878 sec.\n",
      "Iter 190 || Loss: 9.0999 || 10iter: 2.4149 sec.\n",
      "Iter 200 || Loss: 9.3735 || 10iter: 2.4926 sec.\n",
      "Iter 210 || Loss: 7.7816 || 10iter: 2.4450 sec.\n",
      "Iter 220 || Loss: 7.6061 || 10iter: 2.4439 sec.\n",
      "Iter 230 || Loss: 8.8519 || 10iter: 2.5068 sec.\n",
      "Iter 240 || Loss: 7.7002 || 10iter: 2.4359 sec.\n",
      "Iter 250 || Loss: 7.0196 || 10iter: 2.4498 sec.\n",
      "Iter 260 || Loss: 6.8062 || 10iter: 2.4601 sec.\n",
      "Iter 270 || Loss: 7.3335 || 10iter: 2.5477 sec.\n",
      "Iter 280 || Loss: 7.1677 || 10iter: 2.6119 sec.\n",
      "Iter 290 || Loss: 7.0741 || 10iter: 2.5362 sec.\n",
      "Iter 300 || Loss: 6.5247 || 10iter: 2.5334 sec.\n",
      "Iter 310 || Loss: 7.2043 || 10iter: 2.4222 sec.\n",
      "Iter 320 || Loss: 7.2233 || 10iter: 2.4321 sec.\n",
      "Iter 330 || Loss: 7.1088 || 10iter: 2.4494 sec.\n",
      "Iter 340 || Loss: 6.7640 || 10iter: 2.4340 sec.\n",
      "Iter 350 || Loss: 7.2225 || 10iter: 2.4194 sec.\n",
      "Iter 360 || Loss: 7.3903 || 10iter: 2.5503 sec.\n",
      "Iter 370 || Loss: 6.3046 || 10iter: 2.4288 sec.\n",
      "Iter 380 || Loss: 6.8197 || 10iter: 2.4315 sec.\n",
      "Iter 390 || Loss: 6.5198 || 10iter: 2.4326 sec.\n",
      "Iter 400 || Loss: 6.4928 || 10iter: 2.4053 sec.\n",
      "Iter 410 || Loss: 6.2727 || 10iter: 2.4916 sec.\n",
      "Iter 420 || Loss: 6.9002 || 10iter: 2.4694 sec.\n",
      "Iter 430 || Loss: 6.6029 || 10iter: 2.4848 sec.\n",
      "Iter 440 || Loss: 7.2432 || 10iter: 2.4644 sec.\n",
      "Iter 450 || Loss: 7.0458 || 10iter: 2.4253 sec.\n",
      "Iter 460 || Loss: 5.6699 || 10iter: 2.4601 sec.\n",
      "Iter 470 || Loss: 6.1264 || 10iter: 2.4367 sec.\n",
      "Iter 480 || Loss: 6.2665 || 10iter: 2.4465 sec.\n",
      "Iter 490 || Loss: 6.1826 || 10iter: 2.4232 sec.\n",
      "Iter 500 || Loss: 5.6577 || 10iter: 2.4671 sec.\n",
      "Iter 510 || Loss: 6.2202 || 10iter: 2.3719 sec.\n",
      "-------------\n",
      "epoch 1 || Epoch_TRAIN_Loss:5458.7002 ||Epoch_VAL_Loss:0.0000\n",
      "timer:  131.5345 sec.\n",
      "lr is: 0.001\n",
      "-------------\n",
      "Epoch 2/200\n",
      "-------------\n",
      "(train)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/torch/nn/functional.py:2457: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\n",
      "  warnings.warn(\"nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\")\n",
      "/home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/torch/nn/functional.py:2539: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
      "  \"See the documentation of nn.Upsample for details.\".format(mode))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 520 || Loss: 5.7972 || 10iter: 2.2280 sec.\n",
      "Iter 530 || Loss: 5.9533 || 10iter: 2.6162 sec.\n",
      "Iter 540 || Loss: 5.7764 || 10iter: 2.4010 sec.\n",
      "Iter 550 || Loss: 5.6730 || 10iter: 2.4691 sec.\n",
      "Iter 560 || Loss: 6.1579 || 10iter: 2.4377 sec.\n",
      "Iter 570 || Loss: 6.1104 || 10iter: 2.5114 sec.\n",
      "Iter 580 || Loss: 6.3605 || 10iter: 2.5322 sec.\n",
      "Iter 590 || Loss: 5.7485 || 10iter: 2.4497 sec.\n",
      "Iter 600 || Loss: 5.4334 || 10iter: 2.4007 sec.\n",
      "Iter 610 || Loss: 6.1932 || 10iter: 2.4010 sec.\n",
      "Iter 620 || Loss: 6.2750 || 10iter: 2.5245 sec.\n",
      "Iter 630 || Loss: 5.5166 || 10iter: 2.4488 sec.\n",
      "Iter 640 || Loss: 5.9516 || 10iter: 2.4754 sec.\n",
      "Iter 650 || Loss: 6.2545 || 10iter: 2.4722 sec.\n",
      "Iter 660 || Loss: 5.5212 || 10iter: 2.5185 sec.\n",
      "Iter 670 || Loss: 6.3648 || 10iter: 2.5049 sec.\n",
      "Iter 680 || Loss: 6.2307 || 10iter: 2.4118 sec.\n",
      "Iter 690 || Loss: 6.1977 || 10iter: 2.3956 sec.\n",
      "Iter 700 || Loss: 5.8070 || 10iter: 2.4754 sec.\n",
      "Iter 710 || Loss: 6.1094 || 10iter: 2.5198 sec.\n",
      "Iter 720 || Loss: 6.0915 || 10iter: 2.4162 sec.\n",
      "Iter 730 || Loss: 5.8599 || 10iter: 2.4363 sec.\n",
      "Iter 740 || Loss: 5.5504 || 10iter: 2.4337 sec.\n",
      "Iter 750 || Loss: 6.2124 || 10iter: 2.4346 sec.\n",
      "Iter 760 || Loss: 5.3055 || 10iter: 2.4143 sec.\n",
      "Iter 770 || Loss: 5.4552 || 10iter: 2.4392 sec.\n",
      "Iter 780 || Loss: 5.2544 || 10iter: 2.4271 sec.\n",
      "Iter 790 || Loss: 5.5677 || 10iter: 2.4949 sec.\n",
      "Iter 800 || Loss: 6.3410 || 10iter: 2.4134 sec.\n",
      "Iter 810 || Loss: 5.4767 || 10iter: 2.4217 sec.\n",
      "Iter 820 || Loss: 5.9707 || 10iter: 2.4438 sec.\n",
      "Iter 830 || Loss: 6.0001 || 10iter: 2.4367 sec.\n",
      "Iter 840 || Loss: 5.3524 || 10iter: 2.4121 sec.\n",
      "Iter 850 || Loss: 5.7823 || 10iter: 2.4232 sec.\n",
      "Iter 860 || Loss: 5.8247 || 10iter: 2.4940 sec.\n",
      "Iter 870 || Loss: 5.7410 || 10iter: 2.5010 sec.\n",
      "Iter 880 || Loss: 5.5319 || 10iter: 2.4671 sec.\n",
      "Iter 890 || Loss: 5.6665 || 10iter: 2.5809 sec.\n",
      "Iter 900 || Loss: 5.7166 || 10iter: 2.4492 sec.\n",
      "Iter 910 || Loss: 5.5872 || 10iter: 2.4274 sec.\n",
      "Iter 920 || Loss: 5.5161 || 10iter: 2.4598 sec.\n",
      "Iter 930 || Loss: 5.5896 || 10iter: 2.5045 sec.\n",
      "Iter 940 || Loss: 5.8203 || 10iter: 2.4302 sec.\n",
      "Iter 950 || Loss: 5.2177 || 10iter: 2.4344 sec.\n",
      "Iter 960 || Loss: 5.9388 || 10iter: 2.4054 sec.\n",
      "Iter 970 || Loss: 5.4173 || 10iter: 2.4483 sec.\n",
      "Iter 980 || Loss: 5.7206 || 10iter: 2.3948 sec.\n",
      "Iter 990 || Loss: 5.8024 || 10iter: 2.4011 sec.\n",
      "Iter 1000 || Loss: 5.8832 || 10iter: 2.4723 sec.\n",
      "Iter 1010 || Loss: 5.7052 || 10iter: 2.4527 sec.\n",
      "Iter 1020 || Loss: 5.3743 || 10iter: 2.5268 sec.\n",
      "Iter 1030 || Loss: 5.3763 || 10iter: 2.3385 sec.\n",
      "-------------\n",
      "epoch 2 || Epoch_TRAIN_Loss:2990.1862 ||Epoch_VAL_Loss:0.0000\n",
      "timer:  128.7882 sec.\n",
      "lr is: 0.001\n",
      "-------------\n",
      "Epoch 3/200\n",
      "-------------\n",
      "(train)\n",
      "Iter 1040 || Loss: 5.4775 || 10iter: 2.9912 sec.\n",
      "Iter 1050 || Loss: 5.6048 || 10iter: 2.4648 sec.\n",
      "Iter 1060 || Loss: 5.4771 || 10iter: 2.4514 sec.\n",
      "Iter 1070 || Loss: 5.5806 || 10iter: 2.4716 sec.\n",
      "Iter 1080 || Loss: 5.4723 || 10iter: 2.4636 sec.\n",
      "Iter 1090 || Loss: 5.2116 || 10iter: 2.4322 sec.\n",
      "Iter 1100 || Loss: 5.4149 || 10iter: 2.5079 sec.\n",
      "Iter 1110 || Loss: 6.4393 || 10iter: 2.4902 sec.\n",
      "Iter 1120 || Loss: 5.0002 || 10iter: 2.3941 sec.\n",
      "Iter 1130 || Loss: 5.2053 || 10iter: 2.4851 sec.\n",
      "Iter 1140 || Loss: 5.0534 || 10iter: 2.4310 sec.\n",
      "Iter 1150 || Loss: 4.9530 || 10iter: 2.5165 sec.\n",
      "Iter 1160 || Loss: 5.3818 || 10iter: 2.4346 sec.\n",
      "Iter 1170 || Loss: 4.7616 || 10iter: 2.5481 sec.\n",
      "Iter 1180 || Loss: 5.2588 || 10iter: 2.4615 sec.\n",
      "Iter 1190 || Loss: 5.1422 || 10iter: 2.4058 sec.\n",
      "Iter 1200 || Loss: 5.1943 || 10iter: 2.4227 sec.\n",
      "Iter 1210 || Loss: 5.0407 || 10iter: 2.4333 sec.\n",
      "Iter 1220 || Loss: 5.5524 || 10iter: 2.4465 sec.\n",
      "Iter 1230 || Loss: 5.2062 || 10iter: 2.5187 sec.\n",
      "Iter 1240 || Loss: 5.2591 || 10iter: 2.4092 sec.\n",
      "Iter 1250 || Loss: 5.5180 || 10iter: 2.4149 sec.\n",
      "Iter 1260 || Loss: 5.2911 || 10iter: 2.4935 sec.\n",
      "Iter 1270 || Loss: 5.4496 || 10iter: 2.4093 sec.\n",
      "Iter 1280 || Loss: 5.4237 || 10iter: 2.4310 sec.\n",
      "Iter 1290 || Loss: 5.2557 || 10iter: 2.4401 sec.\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 200\n",
    "train_model(net, dataloaders_dict, criterion, optimizer, num_epochs=num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
